{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_cmfd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanyajais04/copy_moveFrogeryDetection/blob/main/Test_cmfd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDrf2KxHrw_9"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBGRh3wsr2Po",
        "outputId": "2e0f8ffb-b412-4851-c5ec-a8298785b0d3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNOG5Tt2sGqJ"
      },
      "source": [
        "class DataGen(keras.utils.Sequence):\n",
        "    def __init__(self, ids, path, batch_size=20, image_h=256, image_w = 256):\n",
        "        self.ids = ids\n",
        "        self.path = path\n",
        "        self.batch_size = batch_size\n",
        "        self.image_h = image_h\n",
        "        self.image_w = image_w\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __load__(self, id_name):\n",
        "        ## Path\n",
        "        image_path = os.path.join(self.path,'test_img', id_name)\n",
        "        if '.png' in id_name:\n",
        "            stringforid = id_name.strip('.png')\n",
        "        if '.jpg' in id_name:\n",
        "            stringforid = id_name.strip('.jpg')\n",
        "        stringId = stringforid+'_mask.png'\n",
        "        \n",
        "        mask_path = os.path.join(self.path,'test_mask', stringId)      \n",
        "\n",
        "        ## Reading Imag\n",
        "        image = cv2.imread(image_path, 1)\n",
        "        image = cv2.resize(image, (self.image_h, self.image_w))\n",
        "        mask = np.zeros((self.image_h, self.image_w, 1))\n",
        "           \n",
        "        mask_img = cv2.imread(mask_path, 0)\n",
        "        mask_img = cv2.resize(mask_img, (self.image_h, self.image_w))\n",
        "        \n",
        "        mask_img = np.expand_dims(mask_img, axis=-1)\n",
        "        mask = np.maximum(mask, mask_img)\n",
        "                \n",
        "        ## Normalizaing \n",
        "        image = image/255.0\n",
        "        mask = mask/255.0\n",
        "        \n",
        "        return image, mask\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if(index+1)*self.batch_size > len(self.ids):\n",
        "            self.batch_size = len(self.ids) - index*self.batch_size\n",
        "        \n",
        "        files_batch = self.ids[index*self.batch_size : (index+1)*self.batch_size]\n",
        "        \n",
        "        image = []\n",
        "        mask  = []\n",
        "        \n",
        "        for id_name in files_batch:\n",
        "            _img, _mask = self.__load__(id_name)\n",
        "            image.append(_img)\n",
        "            mask.append(_mask)\n",
        "            \n",
        "        image = np.array(image)\n",
        "        mask  = np.array(mask)\n",
        "        \n",
        "        return image, mask\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        pass\n",
        "    \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.ids)/float(self.batch_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_awndRFtDxQ"
      },
      "source": [
        "image_h = 256\n",
        "image_w = 256\n",
        "\n",
        "#change path of train with test and images also\n",
        "#Path of test images\n",
        "img_path = '/content/drive/MyDrive/CoMoFoD/Test'\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "batch_size = 20\n",
        "\n",
        "##Ids for test images \n",
        "ids = next(os.walk(os.path.join(img_path,'test_img')))[2]\n",
        "data = DataGen(ids, img_path, image_h=image_h, image_w = image_w, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZz9N8Db7K9f"
      },
      "source": [
        "def conv(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):  \n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    c = keras.layers.Activation('relu')(c)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(c)\n",
        "    c = keras.layers.Activation('relu')(c)\n",
        "    return c\n",
        "\n",
        "def max_pool(x):\n",
        "    p = keras.layers.MaxPool2D((2, 2), (2, 2))(x)\n",
        "    return p\n",
        "\n",
        "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    us = keras.layers.UpSampling2D((2, 2))(x)\n",
        "    concat = keras.layers.Concatenate()([us, skip])\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(concat)\n",
        "    c = keras.layers.Activation('relu')(c)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(c)\n",
        "    c = keras.layers.Activation('relu')(c)\n",
        "    return c\n",
        "\n",
        "def bottleneck(x, filters, kernel_size=(5, 5), padding=\"same\", strides=1):\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    c = keras.layers.Activation('relu')(c)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(c)\n",
        "    c = keras.layers.Activation('relu')(c)\n",
        "    return c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPpmHriV7PUx"
      },
      "source": [
        "def UNet():\n",
        "    f = [16, 32, 64, 128, 256]\n",
        "    image_size= 256\n",
        "    s0 = keras.layers.Input((image_size, image_size, 3))\n",
        "    pt0 = keras.layers.experimental.preprocessing.RandomRotation(0.2)(s0)\n",
        "    \n",
        "    s1 = keras.layers.MaxPool2D((2, 2), (2, 2))(s0)\n",
        "    pt1 = keras.layers.experimental.preprocessing.RandomRotation(0.2)(s1)\n",
        "\n",
        "    s2 = keras.layers.MaxPool2D((2, 2), (2, 2))(s1)\n",
        "    pt2 = keras.layers.experimental.preprocessing.RandomRotation(0.2)(s2)\n",
        "\n",
        "    s3 = keras.layers.MaxPool2D((2, 2), (2, 2))(s2)\n",
        "    pt3 = keras.layers.experimental.preprocessing.RandomRotation(0.2)(s3)\n",
        "\n",
        "    c0 = conv(pt0, f[0])\n",
        "    p0 = max_pool(c0)\n",
        "    c1 = conv(pt1, f[1])\n",
        "    l1 = keras.layers.Concatenate()([p0,c1])\n",
        "    p1 = max_pool(l1)\n",
        "    \n",
        "    c2 = conv(pt2, f[2])\n",
        "    l2 = keras.layers.Concatenate()([p1,c2])\n",
        "    p2 = max_pool(l2)\n",
        "\n",
        "    c3 = conv(pt3, f[3])\n",
        "    l3 = keras.layers.Concatenate()([p2,c3])\n",
        "    p3 = max_pool(l3)\n",
        "    \n",
        "    bn = bottleneck(p3, f[4])\n",
        "    \n",
        "    u1 = up_block(bn, c3, f[3]) #8 -> 16\n",
        "    u2 = up_block(u1, c2, f[2]) #16 -> 32\n",
        "    u3 = up_block(u2, c1, f[1]) #32 -> 64\n",
        "    u4 = up_block(u3, c0, f[0]) #64 -> 128\n",
        "    \n",
        "    outputs = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n",
        "    model = keras.models.Model(s0, outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRLv8ty047ai"
      },
      "source": [
        "model = UNet()\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9iF_sIqtFrO"
      },
      "source": [
        "#Load weight\n",
        "model.load_weights('/content/drive/MyDrive/project dl/modelweight.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSPXYwLI6Jh0"
      },
      "source": [
        "def evaluation_matrix(gt,r):\n",
        "    tp = 0 \n",
        "    fp = 0\n",
        "    tn = 0\n",
        "    fn = 0\n",
        "    size = gt.shape\n",
        "    m = size[0]\n",
        "    n = size[1]\n",
        "    for i in range(0,gt.shape[0]):\n",
        "        for j in range(0,gt.shape[1]):\n",
        "            if r[i][j]==0 and gt[i][j]==0:\n",
        "                tp=tp+1\n",
        "            elif r[i][j]==0 and gt[i][j]==1:\n",
        "                fp = fp+1\n",
        "            elif r[i][j]==1 and gt[i][j]==0:\n",
        "                fn = fn+1\n",
        "            elif r[i][j]==1 and gt[i][j]==1:\n",
        "                tn = tn+1\n",
        "    #prec = tp/(tp+fp)\n",
        "    #recall = tp/(tp+fn)\n",
        "    #acc = (tp+tn)/(tp+tn+fp+fn)\n",
        "    #tnr = tn/(tn+fp)\n",
        "    #fpr = fp/(fp+tn)\n",
        "    #fnr = fn/(fn+tp)\n",
        "    #csi = tp/(tp+fn+fp)\n",
        "    #f1 = 2*((prec*recall)/(prec+recall))\n",
        "    #mcc = (tp*tn-fp*fn)/math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
        "    return tp,tn,fp,fn\n",
        "#prec,recall,acc,tnr,fnr,f1,mcc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h6LwN_q6TgN"
      },
      "source": [
        "x, y = data.__getitem__(6)\n",
        "result1 = model.predict(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ6lT2BQ7LiZ"
      },
      "source": [
        "result = result1>0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8Z8WHXc6XcG"
      },
      "source": [
        "  for j in range(0,20):\n",
        "    fig = plt.figure(figsize=(20,10))\n",
        "\n",
        "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "    ax = fig.add_subplot(1, 3, 1)\n",
        "    b,g,r = cv2.split(x[j])       # get b,g,r\n",
        "    rgb_img = cv2.merge([r,g,b]) \n",
        "    ax.imshow(rgb_img)\n",
        "\n",
        "    ax = fig.add_subplot(1, 3, 2)\n",
        "    ax.imshow(np.reshape(y[j]*255, (image_h, image_w)), cmap=\"gray\")\n",
        "\n",
        "    ax = fig.add_subplot(1, 3, 3)\n",
        "    ax.imshow(np.reshape(result[j]*255, (image_h, image_w)), cmap=\"gray\")\n",
        "    \n",
        "    tp,tn,fp,fn = evaluation_matrix(y[j],result[j])\n",
        "    print(str(tp)+','+str(tn)+','+str(fp)+','+str(fn))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}